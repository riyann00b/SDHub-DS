![ML Overview](https://iq.opengenus.org/content/images/2022/05/data-science-related-domains.png)


+ NLP : Natural language processing

example: Flipkart product recommadation engine (suggest products to buy)

Deep Learning: flipkart AI summery based on comments and review (deeplearing with nlp)

process of processing comments and review is NLP then feed the structed data in Deep learing models

NLP + ML

NLP + DL

example PowerBi vistual : Q&A and AI vistuals

example ChatGPT: it uses all techniques

---

Models (Engine) (Models are like Engines)

LLM (engine) -> AI agents (ChatGPT) -> workflow -> Gen AI -> Agentic AI -> MCP

---

Model building:
2 ways to build model

1. ML = 90% of time we use ML (Cheap / quick traing and testing)
2. DL = 10% of work is based on DL (expensive takes times to train and test)

GPT-Model :

GPT is a model and chatgpt is the application of the this model 

it took all the public data to train its model

---

Models works on probabilities 

eg: explain me mathematics

(combines all the knowledge and gives us the final output)

---

ML (Machine learning): process to make machine learn from the data, (gives customize resposes based on its cognetics skills)

---

ML life cycle


life cycle of DS

EDA
1. problem / business requirements
2. data collection
3. data preprocessing
4. data analysis
5. data vistulizations

ML/DL

6. model building (taring)
7. model testing
8. Feature engineering / standardisation / feature scaling / normalising columns
9. optimisation and deployment

EDA -> Data Preparation for model (if you haven't already) (convert all columns into numerical data -> Feature/columns/Dimension/  Scaling -> data splinting (test and train data generality is in 80:20 ratio using sampling(statistics (convenient sampling / random sampling)) (model traing: selecting a model -> then model testing(measures))) -> optimize and deploy  

Feature scaling (use to remove Bias)
example

| Gender | Height | weight |
| ------ | ------ | ------ |
| ?      | 165    | 80     |
| ?      | 175    | 75     |
| ?      | 180    | 80     |
| ?      | 150    | 50     |

we normalise/feature engineering / scaling to normalise this data so that it is not bias on height since it have way higher numbers 

when you have to many columns you test correlation as well

use NLP in data preparation if data is in natural language

---

Machine Learning

Machine learning have predefined process known as Algorithms

1. Supervised ML : 80% usage, known output / Labelled data data is numerical -> regression eg weather forecasting and categorical->  classification eg spam email
2. Unsupervised ML : 15% usage, Unknown output / Un-Labelled data, clustering -> YouTube / instagram / dimensionality reduction -> reducing number of column type of correlation done during prepossessing or preparing reducing features PCA (principle component analysis)
3. Reinforcement ML : 5% usages, learn using trail and error/ hot and try / reward and penalty , known output, eg robotics and self driving cars 

---


> [!important] 
> Time management skills



---

Use Case: house price prediction
in excel : not good / plain equation base
number of bedroom / how old / area = price 
regression model\

ML model:  good / have more parameter

